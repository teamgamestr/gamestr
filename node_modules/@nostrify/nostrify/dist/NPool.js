import { getFilterLimit } from "nostr-tools";
import { CircularSet } from "./utils/CircularSet.js";
import { Machina } from "./utils/Machina.js";
import { NSet } from "./NSet.js";
class NPool {
  _relays = /* @__PURE__ */ new Map();
  opts;
  constructor(opts) {
    this.opts = opts;
  }
  /** Get or create a relay instance for the given URL. */
  relay(url) {
    const relay = this._relays.get(url);
    if (relay) {
      return relay;
    } else {
      const relay2 = this.opts.open(url);
      this._relays.set(url, relay2);
      return relay2;
    }
  }
  /** Returns a new pool instance that uses the given relays. Connections are shared with the original pool. */
  group(urls) {
    return new NPool({
      open: (url) => this.relay(url),
      reqRouter: (filters) => new Map(urls.map((url) => [url, filters])),
      eventRouter: () => urls
    });
  }
  get relays() {
    return this._relays;
  }
  /**
   * Sends a `REQ` to relays based on the configured `reqRouter`.
   *
   * `EVENT` messages from the selected relays are yielded.
   * `EOSE` and `CLOSE` messages are only yielded when all relays have emitted them.
   *
   * Deduplication of `EVENT` messages is attempted, so that each event is only yielded once.
   * A circular set of 1000 is used to track seen event IDs, so it's possible that very
   * long-running subscriptions (with over 1000 results) may yield duplicate events.
   */
  async *req(filters, opts) {
    const controller = new AbortController();
    const signal = opts?.signal ? AbortSignal.any([opts.signal, controller.signal]) : controller.signal;
    const routes = opts?.relays ? new Map(opts.relays.map((url) => [url, filters])) : await this.opts.reqRouter(filters);
    if (routes.size < 1) {
      return;
    }
    const machina = new Machina(signal);
    const eoses = /* @__PURE__ */ new Set();
    const closes = /* @__PURE__ */ new Set();
    const events = new CircularSet(1e3);
    const relayPromises = [];
    for (const [url, filters2] of routes.entries()) {
      const relay = this.relay(url);
      const relayPromise = (async () => {
        try {
          for await (const msg of relay.req(filters2, { signal })) {
            if (msg[0] === "EOSE") {
              eoses.add(url);
              if (eoses.size === routes.size) {
                machina.push(msg);
              }
            }
            if (msg[0] === "CLOSED") {
              closes.add(url);
              if (closes.size === routes.size) {
                machina.push(msg);
              }
            }
            if (msg[0] === "EVENT") {
              const [, , event] = msg;
              if (!events.has(event.id)) {
                events.add(event.id);
                machina.push(msg);
              }
            }
          }
        } catch {
        }
      })();
      relayPromises.push(relayPromise);
    }
    try {
      for await (const msg of machina) {
        yield msg;
      }
    } finally {
      controller.abort();
      await Promise.allSettled(relayPromises);
    }
  }
  /**
   * Events are sent to relays according to the `eventRouter`.
   * Returns a fulfilled promise if ANY relay accepted the event,
   * or a rejected promise if ALL relays rejected or failed to publish the event.
   */
  async event(event, opts) {
    const relayUrls = opts?.relays ?? await this.opts.eventRouter(event);
    if (!relayUrls.length) {
      return;
    }
    await Promise.any(
      relayUrls.map((url) => this.relay(url).event(event, opts))
    );
  }
  /**
   * This method calls `.req` internally and then post-processes the results.
   * Please read the definition of `.req`.
   *
   * - The strategy is to seek regular events quickly, and to wait to find the latest versions of replaceable events.
   * - Filters for replaceable events will wait for all relays to `EOSE` (or `CLOSE`, or for the signal to be aborted) to ensure the latest event versions are retrieved.
   * - Filters for regular events will stop as soon as the filters are fulfilled.
   * - Events are deduplicated, sorted, and only the latest version of replaceable events is kept.
   * - If the signal is aborted, this method will return partial results instead of throwing.
   *
   * To implement a custom strategy, call `.req` directly.
   */
  async query(filters, opts) {
    const map = /* @__PURE__ */ new Map();
    const events = new NSet(map);
    const limit = filters.reduce(
      (result, filter) => result + getFilterLimit(filter),
      0
    );
    if (limit === 0) return [];
    try {
      for await (const msg of this.req(filters, opts)) {
        if (msg[0] === "EOSE") break;
        if (msg[0] === "EVENT") events.add(msg[2]);
        if (msg[0] === "CLOSED") break;
      }
    } catch {
    }
    if (filters.some((filter) => typeof filter.search === "string")) {
      return [...map.values()];
    } else {
      return [...events];
    }
  }
  /** Close all the relays in the pool. */
  async close() {
    await Promise.all(
      [...this._relays.values()].map((relay) => relay.close())
    );
  }
  async [Symbol.asyncDispose]() {
    await this.close();
  }
}
export {
  NPool
};
